ğŸ“¦ CSV Sales Processor â€“ Backend Developer Project
This is a full-stack application that allows users to upload large CSV files of sales data. The backend streams and processes the CSV to aggregate total sales per department, then returns a downloadable CSV file along with performance metrics.

ğŸš€ How to Run the App
ğŸ“ Clone the Repo
bash
Copy
Edit
git clone https://github.com/your-username/csv-sales-processor.git
cd csv-sales-processor
ğŸ› ï¸ Backend Setup
bash
Copy
Edit
cd backend
npm install
cp .env.example .env
# Set your API_KEY in .env
npm run dev
Runs on http://localhost:3000

ğŸŒ Frontend Setup
bash
Copy
Edit
cd frontend
npm install
npm run dev
Runs on http://localhost:3001 (or whichever port Vite/Next.js chooses)

ğŸ§ª How to Test
ğŸ”¬ Unit Tests (Backend)
bash
Copy
Edit
cd backend
npm run test
This runs unit tests for:

parseCsv (CSV parsing logic)

aggregateSales (sales aggregation logic)

fileWriter (writes processed CSV file)

Test framework: Jest
Test coverage is printed in the terminal. To view coverage summary:

bash
Copy
Edit
npm run test:coverage
ğŸ“‚ File Structure
pgsql
Copy
Edit
project-root/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ uploadController.ts
â”‚   â”‚   â””â”€â”€ downloadController.ts
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ csvProcessor.ts
â”‚   â”‚   â”œâ”€â”€ fileWriter.ts
â”‚   â”‚   â””â”€â”€ authMiddleware.ts
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ generateFilename.ts
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ csvProcessor.test.ts
â”‚   â”œâ”€â”€ public/processed/  <-- generated downloadable files
â”‚   â””â”€â”€ server.ts
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/ or app/
â”‚   â”‚   â””â”€â”€ index.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ FileUploader.tsx
â”‚   â””â”€â”€ styles/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
ğŸ§  Algorithm Explanation
âœ… What it does:
Reads CSV with stream-based parser (csv-parser)

Aggregates sales totals per department using a Map

Writes the output as a new CSV file using fs.createWriteStream

Generates a UUID-named file for download

Returns metrics (processing time and department count) in the response

ğŸ§® Memory Efficiency Strategy:
âœ… Uses streaming (fs.createReadStream) to avoid loading the entire CSV into memory

âœ… Processes line by line with csv-parser

âœ… Aggregates in-memory using a Map (O(1) insert/lookup)

âœ… Writes output using fs.createWriteStream to avoid buffering large strings

This makes the app capable of processing very large CSV files without crashing.

ğŸ“ˆ Estimated Time & Space Complexity
Step	Time Complexity	Space Complexity
CSV Parsing (stream)	O(n)	O(d)
Aggregation	O(n)	O(d)
File Writing	O(d)	O(d)

n: number of rows in the CSV

d: number of unique departments (usually small)

Streaming ensures space is not dependent on n, which keeps memory usage low.

ğŸ” API Security
Upload and download routes are protected with an API key

Users must include the x-api-key header in every request

Example:

bash
Copy
Edit
curl -X POST http://localhost:3000/upload \
  -H "x-api-key: your_secret_key" \
  -F "file=@sales.csv"
